{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c552694c",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f91a2-ef75-44c9-8743-962ff176b72b",
   "metadata": {},
   "source": [
    "This is a Python notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b897c533",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34608916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter config\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'  # Or 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from itertools import chain, combinations, zip_longest, tee, islice\n",
    "from typing import *\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from scipy.stats import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.mixture import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "memory = Memory('./')\n",
    "#plt.style.use('seaborn-whitegrid')  # Set the aesthetic style of the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c89b1c8",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea4201f-078c-42b3-b48d-bc3bb3637964",
   "metadata": {},
   "source": [
    "Import data from csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0abe431",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('train_processed.csv')\n",
    "test_data = pd.read_csv('test_processed.csv')\n",
    "\n",
    "training_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8a265-b350-4863-a99b-1ec22a39d825",
   "metadata": {},
   "source": [
    "Convert non-numeric labels to numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = {\n",
    "    'Sex': LabelEncoder(),\n",
    "    'Ticket': LabelEncoder(),\n",
    "    'Embarked': LabelEncoder(),\n",
    "    'NameTitle': LabelEncoder(),\n",
    "    'FirstName': LabelEncoder(),\n",
    "    'MiddleNames': LabelEncoder(),\n",
    "    'LastName': LabelEncoder(),\n",
    "    'Deck': LabelEncoder(),\n",
    "    'WithFamily': LabelEncoder(),\n",
    "}\n",
    "for feature, label_encoder in label_encoders.items():\n",
    "    label_encoder.fit(pd.concat((training_data[feature], test_data[feature])))\n",
    "    training_data[feature] = label_encoder.transform(training_data[feature])\n",
    "    test_data[feature] = label_encoder.transform(test_data[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef01c7-7e32-4f73-a23f-7d4541d010aa",
   "metadata": {},
   "source": [
    "In what follows, we detail our attempts to generating a machine learning model.\n",
    "We want to only include working code in this Jupyter notebook so we only present our first and last attempt.\n",
    "We direct readers curious about our prior attempts to older versions of this notebook.\n",
    "They are available at the following links in the Git history:\n",
    "\n",
    "- [Attempt 1]: `git checkout attempt-01`\n",
    "- [Attempt 2]: `git checkout attempt-02`\n",
    "- [Attempt 3]: `git checkout attempt-03`\n",
    "- [Attempt 4]: `git checkout attempt-04`\n",
    "- [Attempt 5]: `git checkout attempt-05`\n",
    "- [Attempt 6]: `git checkout attempt-06`\n",
    "- [Attempt 7]: `git checkout attempt-07`\n",
    "- [Attempt 8]: `git checkout attempt-08`\n",
    "\n",
    "[Attempt 1]: https://github.com/0x326/miami-university-cse-627-group-project/blob/attempt-01/03_Machine_Learning.ipynb\n",
    "[Attempt 2]: https://github.com/0x326/miami-university-cse-627-group-project/blob/attempt-02/03_Machine_Learning.ipynb\n",
    "[Attempt 3]: https://github.com/0x326/miami-university-cse-627-group-project/blob/attempt-03/03_Machine_Learning.ipynb\n",
    "[Attempt 4]: https://github.com/0x326/miami-university-cse-627-group-project/blob/attempt-04/03_Machine_Learning.ipynb\n",
    "[Attempt 5]: https://github.com/0x326/miami-university-cse-627-group-project/blob/attempt-05/03_Machine_Learning.ipynb\n",
    "[Attempt 6]: https://github.com/0x326/miami-university-cse-627-group-project/blob/attempt-06/03_Machine_Learning.ipynb\n",
    "[Attempt 7]: https://github.com/0x326/miami-university-cse-627-group-project/blob/attempt-07/03_Machine_Learning.ipynb\n",
    "[Attempt 8]: https://github.com/0x326/miami-university-cse-627-group-project/blob/attempt-08/03_Machine_Learning.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e74947",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2187f3-8ef3-4755-b8ba-1d676714e41c",
   "metadata": {},
   "source": [
    "### Selecting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6608bb4",
   "metadata": {},
   "source": [
    "We will initally select the features which we believe would most affect the survival odds of an individual aboard the titanic\n",
    "\n",
    "We decide to keep the following features:\n",
    "\n",
    "* **PClass** - the class of the ticket, as we all know this had a large say in deciding who got on the escape boats\n",
    "* **Age** - An older person is weaker than a younger one on average.\n",
    "* **Fare** - Someone who paid a lot more money would be in a far different position than someone who did not\n",
    "* **Embarked** - Depending on the port they got on, (might play a role, not sure.. might get rid of this in other attempt)\n",
    "* **Deck** - The deck of the boat the person was staying is important when a boat is floating\n",
    "* **FamilySize** - If an individual had a family it is possible that they gave up their spot on an escape boat or attempted to rescue them\n",
    "* **FarePerPerson** - The amount paid per person (based on family size) could indicate how they were treated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc62a8-6b60-42de-8d32-83fa93c5a57f",
   "metadata": {},
   "source": [
    "## Classifier Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc699174",
   "metadata": {},
   "source": [
    "Using information seen in <https://www.kaggle.com/mosleylm/titanic-data-set-exploration/execution#II.-Format-Data> we decide that we will test many different classifiers and then select the highest performing one based on the F1 score.\n",
    "We will use a stratified 10-fold cross validation in order to train and test on all of our data.\n",
    "\n",
    "We test the following classifiers:\n",
    "\n",
    "* **Gradient Boosting**\n",
    "* **Random Forest**\n",
    "* **KNeighbors**\n",
    "* **SVC**\n",
    "* **Decision Tree**\n",
    "* **Ada Boost**\n",
    "* **GaussianNB**\n",
    "* **Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f772d-5b6c-4be0-8b63-ae4d19b0ff88",
   "metadata": {},
   "source": [
    "## Attempt 2-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0580fb9-70c0-4f3f-9759-fbef9bc9c302",
   "metadata": {},
   "source": [
    "### Code definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0466e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7a0ded",
   "metadata": {},
   "source": [
    "Based on <https://docs.python.org/3/library/itertools.html#itertools-recipes>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73982be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> (1,2,3) (1,2) (1,3) (2,3) (1,) (2,) (3,) ()\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in reversed(range(len(s)+1)))\n",
    "\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dee222",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_number = '#WORKERS'  # Will be replaced with number using sed. See bash script later on\n",
    "total_workers = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44333ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(NamedTuple):\n",
    "    name: str\n",
    "    features: Sequence[str]\n",
    "\n",
    "\n",
    "class ClassifierResult(NamedTuple):\n",
    "    classifier: Any\n",
    "    test_predictions: npt.ArrayLike\n",
    "    f1_score: np.float64\n",
    "    accuracy_score: np.float64\n",
    "\n",
    "\n",
    "class AllClassifierResults(NamedTuple):\n",
    "    classifiers: Dict[Classifier, Any]\n",
    "    classifiers_by_f1_score: Dict[Classifier, np.float64]\n",
    "    classifiers_by_accuracy_score: Dict[Classifier, np.float64]\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'KNeighborsClassifier': lambda: KNeighborsClassifier(5),\n",
    "    'SVC': lambda: SVC(probability=True),\n",
    "    'DecisionTreeClassifier': lambda: DecisionTreeClassifier(),\n",
    "    'RandomForestClassifier': lambda: RandomForestClassifier(),\n",
    "    'AdaBoostClassifier': lambda: AdaBoostClassifier(),\n",
    "    'GradientBoostingClassifier': lambda: GradientBoostingClassifier(),\n",
    "    'GaussianNB': lambda: GaussianNB(),\n",
    "    'LogisticRegression': lambda: LogisticRegression(),\n",
    "}\n",
    "\n",
    "\n",
    "@delayed\n",
    "@memory.cache\n",
    "def train_classifier(selected_features, train_true, classifier_name, num_splits=10) -> ClassifierResult:\n",
    "    X = training_data[list(selected_features)]\n",
    "    X = X.values\n",
    "    y = training_data[list(train_true)]\n",
    "    y = np.asarray(y).reshape(-1)\n",
    "\n",
    "    splitter = StratifiedShuffleSplit(n_splits=num_splits, test_size=0.1, random_state=0)\n",
    "    classifier = classifiers[classifier_name]()\n",
    "\n",
    "    average_f1_score = np.float64()\n",
    "    average_accuracy_score = np.float64()\n",
    "    for train_idx, test_idx in splitter.split(X, y):  # 10 folds\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        Y_train, Y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        classifier.fit(X_train, Y_train)\n",
    "\n",
    "        test_predictions = classifier.predict(X_test)\n",
    "        average_f1_score += f1_score(Y_test, test_predictions)\n",
    "        average_accuracy_score += accuracy_score(Y_test, test_predictions)\n",
    "\n",
    "    average_f1_score /= num_splits\n",
    "    average_accuracy_score /= num_splits\n",
    "\n",
    "    return ClassifierResult(classifier=classifier,\n",
    "                            test_predictions=test_predictions,\n",
    "                            f1_score=average_f1_score,\n",
    "                            accuracy_score=average_accuracy_score)\n",
    "\n",
    "\n",
    "def train_all_classifiers(n_jobs=os.cpu_count()) -> AllClassifierResults:\n",
    "    train_true = ('Survived',)\n",
    "    assumed_features = (\n",
    "        'Sex',\n",
    "        'Pclass',\n",
    "        'Age',\n",
    "    )\n",
    "    excluded_features = (\n",
    "        'NameTitle',\n",
    "        'FirstName',\n",
    "        'MiddleNames',\n",
    "        'LastName',\n",
    "    )\n",
    "    candidate_features = iter(training_data)\n",
    "    candidate_features = filter(lambda feature: feature not in train_true, candidate_features)\n",
    "    candidate_features = filter(lambda feature: feature not in assumed_features, candidate_features)\n",
    "    candidate_features = filter(lambda feature: feature not in excluded_features, candidate_features)\n",
    "    candidate_features = tuple(candidate_features)\n",
    "\n",
    "    all_classifiers: Dict[Classifier, Any] = {}\n",
    "    classifiers_by_f1_score: Dict[Classifier, np.float64] = defaultdict(int)\n",
    "    classifiers_by_accuracy_score: Dict[Classifier, np.float64] = defaultdict(int)\n",
    "\n",
    "    candidate_features_subsets = ((*assumed_features, *selected_features)\n",
    "                                  for selected_features in powerset(candidate_features))\n",
    "    candidate_features_subsets = filter(lambda features: len(features) > 0, candidate_features_subsets)\n",
    "    candidate_features_subsets = islice(candidate_features_subsets, worker_number - 1, None, total_workers)\n",
    "    candidate_features_subsets_1, candidate_features_subsets_2 = tee(candidate_features_subsets)\n",
    "    del candidate_features_subsets\n",
    "    job_inputs = (Classifier(name=classifier_name, features=selected_features)\n",
    "                  for selected_features in candidate_features_subsets_1\n",
    "                  for classifier_name in classifiers.keys())\n",
    "    job_results = (train_classifier(selected_features, train_true, classifier_name)\n",
    "                   for selected_features in candidate_features_subsets_2\n",
    "                   for classifier_name in classifiers.keys())\n",
    "    if n_jobs == 1:\n",
    "        job_results = Parallel(n_jobs=1)(job_results)\n",
    "    else:\n",
    "        # Group by every 100 * CPU Count\n",
    "        job_results = chain.from_iterable(Parallel(n_jobs=n_jobs, verbose=10)(filter(lambda job: job is not None, partial_job_list))\n",
    "                                          for partial_job_list in grouper(job_results, n_jobs * 100))\n",
    "    \n",
    "    for classifier, results in tqdm(zip(job_inputs, job_results),\n",
    "                                    total=(2 ** len(candidate_features) - 1) * 8):\n",
    "        all_classifiers[classifier] = results.classifier\n",
    "        classifiers_by_f1_score[classifier] = results.f1_score\n",
    "        classifiers_by_accuracy_score[classifier] = results.accuracy_score\n",
    "\n",
    "    return AllClassifierResults(classifiers=all_classifiers,\n",
    "                                classifiers_by_f1_score=classifiers_by_f1_score,\n",
    "                                classifiers_by_accuracy_score=classifiers_by_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f38c72-0d75-4fda-8cd7-16326a9bd34e",
   "metadata": {},
   "source": [
    "### Running Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a8beb-919e-42b0-9241-b976b620d0b3",
   "metadata": {},
   "source": [
    "The following two cells export this Jupyter notebook to a simple IPython script.\n",
    "Copies of this script are made for each worker and the value of `worker_number` is set to `'1'`, `'2'`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    worker_number = int(worker_number)\n",
    "\n",
    "except ValueError:\n",
    "    print('Skipping since we are running in a Jupyter Notebook')\n",
    "    \n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "    gc.collect()\n",
    "    all_results = train_all_classifiers(n_jobs=1)\n",
    "    with open(f'results_{worker_number}.pkl', 'wb') as file:\n",
    "        pickle.dump(all_results, file, protocol=5)\n",
    "    sys.exit(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba85c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "NOTEBOOK=03_Machine_Learning\n",
    "\n",
    "if [[ -e \".${NOTEBOOK}_running\" ]]; then\n",
    "    echo 'Test is already running. If you are sure this is not the case, run:' >&2\n",
    "    echo \"    rm .${NOTEBOOK}_running\" >&2\n",
    "    exit 1\n",
    "fi\n",
    "touch \".${NOTEBOOK}_running\"\n",
    "\n",
    "jupyter nbconvert --to script \"${NOTEBOOK}.ipynb\"\n",
    "for WORKER_NUM in $(seq \"$(nproc)\"); do\n",
    "    sed \"s/#WORKERS/${WORKER_NUM}/g\" \"${NOTEBOOK}.py\" > \"_${NOTEBOOK}_${WORKER_NUM}.py\"\n",
    "    ipython \"_${NOTEBOOK}_${WORKER_NUM}.py\" &\n",
    "done\n",
    "wait\n",
    "\n",
    "rm \".${NOTEBOOK}_running\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9341883-5b40-4375-89b1-0c7633c22c48",
   "metadata": {},
   "source": [
    "### Gathering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a81150",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifiers: Dict[Classifier, Any] = {}\n",
    "classifiers_by_f1_score: Dict[Classifier, np.float64] = {}\n",
    "classifiers_by_accuracy_score: Dict[Classifier, np.float64] = {}\n",
    "\n",
    "for worker_number in range(1, os.cpu_count() + 1):\n",
    "    worker_results: Dict[int, Any] = {}\n",
    "    with open(f'results_{worker_number}.pkl', 'rb') as file:\n",
    "        results = pickle.load(file)\n",
    "        all_classifiers.update(results.classifiers)\n",
    "        classifiers_by_f1_score.update(results.classifiers_by_f1_score)\n",
    "        classifiers_by_accuracy_score.update(results.classifiers_by_accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10fe1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_ranks = pd.DataFrame({\n",
    "                                    'Classifier': [classifier.name for classifier in all_classifiers.keys()],\n",
    "                                    'Feature Count': [len(classifier.features) for classifier in all_classifiers.keys()],\n",
    "                                    'Features': [classifier.features for classifier in all_classifiers.keys()],\n",
    "                                    'F1 Score': [classifiers_by_f1_score[classifier] for classifier in all_classifiers],\n",
    "                                    'Accuracy Score': [classifiers_by_accuracy_score[classifier] for classifier in all_classifiers],\n",
    "                                },\n",
    "                                columns=['Classifier', 'Feature Count', 'Features', 'F1 Score', 'Accuracy Score'])\n",
    "classifier_ranks.sort_values('F1 Score', ascending=False, inplace=True)\n",
    "classifier_ranks.to_csv('classifier_ranks.csv', index=False)\n",
    "classifier_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77767628-011f-4033-8103-1e064c4c9569",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"KNeighbors\", \"SVC\", \"DecisionTree\", \"RandomForest\", \"AdaBoost\", \"GradientBoost\", \"GaussianNB\", \"LogisticRegression\"]\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(keys, f1s.values())\n",
    "max_score = max(f1s.values())\n",
    "plt.plot(max(f1s, key=f1s.get),max_score, 'ro', label=f\"max score: {max_score:.2f}\")\n",
    "plt.title(\"Classifier Investigation\")\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c697a2b1-6c97-44ed-b4a1-dcf458c01662",
   "metadata": {},
   "source": [
    "### Logistic regression seems to the best?? \n",
    "\n",
    "**Next I want to normalize features like in: https://www.kaggle.com/mosleylm/titanic-data-set-exploration/execution#II.-Format-Data**. Maybe score will improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a9fb13",
   "metadata": {},
   "source": [
    "Based on our results it appears that the"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
